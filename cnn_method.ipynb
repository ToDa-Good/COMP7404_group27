{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2970066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6746a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eae5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def get_vis_loader():\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "def get_train_loader(batch_size, transform):\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    return trainloader\n",
    "    \n",
    "def get_test_loader(batch_size, transform):\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    return testloader\n",
    "    \n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "vistrainloader, vistestloader = get_vis_loader()\n",
    "trainloader = get_train_loader(batch_size, transform)\n",
    "testloader = get_test_loader(batch_size, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbc4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvolutionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=5, padding=2, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 120)\n",
    "        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "cnn_net = ConvolutionNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9db3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def get_optimizer(net, lr):\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "def accuracy(output, target):\n",
    "    # get the index of the max log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    return pred.eq(target.view_as(pred)).float().mean()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = get_optimizer(fc_net, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678a29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step(net, inputs, labels):\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    return outputs, loss, labels\n",
    "\n",
    "\n",
    "def train(net, loader, optimizer, max_epoch):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    N = len(loader)\n",
    "    print_interval = (N // 8 // 100 + 1) * 100\n",
    "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, labels = data[0].to(device), data[1].to(device) \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, loss, labels = forward_step(net, images, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_acc += accuracy(outputs, labels).item()\n",
    "            if (i + 1) % print_interval == 0:\n",
    "                print('Epoch: [%d / %d], batches: [%d / %d], loss: %.3f, acc: %.2f' %\n",
    "                      (epoch + 1, max_epoch, i + 1, N, \n",
    "                       running_loss / print_interval, 100 * running_acc / print_interval))\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d37614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1 / 5], batches: [100 / 782], loss: 2.303, acc: 10.56\n",
      "Epoch: [1 / 5], batches: [200 / 782], loss: 2.303, acc: 9.88\n",
      "Epoch: [1 / 5], batches: [300 / 782], loss: 2.303, acc: 10.20\n",
      "Epoch: [1 / 5], batches: [400 / 782], loss: 2.300, acc: 12.47\n",
      "Epoch: [1 / 5], batches: [500 / 782], loss: 2.228, acc: 18.22\n",
      "Epoch: [1 / 5], batches: [600 / 782], loss: 2.067, acc: 22.64\n",
      "Epoch: [1 / 5], batches: [700 / 782], loss: 1.969, acc: 27.39\n",
      "Epoch: [2 / 5], batches: [100 / 782], loss: 1.777, acc: 34.91\n",
      "Epoch: [2 / 5], batches: [200 / 782], loss: 1.673, acc: 38.89\n",
      "Epoch: [2 / 5], batches: [300 / 782], loss: 1.626, acc: 39.88\n",
      "Epoch: [2 / 5], batches: [400 / 782], loss: 1.557, acc: 42.94\n",
      "Epoch: [2 / 5], batches: [500 / 782], loss: 1.543, acc: 44.28\n",
      "Epoch: [2 / 5], batches: [600 / 782], loss: 1.489, acc: 45.23\n",
      "Epoch: [2 / 5], batches: [700 / 782], loss: 1.448, acc: 47.66\n",
      "Epoch: [3 / 5], batches: [100 / 782], loss: 1.361, acc: 49.92\n",
      "Epoch: [3 / 5], batches: [200 / 782], loss: 1.342, acc: 51.61\n",
      "Epoch: [3 / 5], batches: [300 / 782], loss: 1.316, acc: 52.75\n",
      "Epoch: [3 / 5], batches: [400 / 782], loss: 1.307, acc: 53.45\n",
      "Epoch: [3 / 5], batches: [500 / 782], loss: 1.303, acc: 53.56\n",
      "Epoch: [3 / 5], batches: [600 / 782], loss: 1.268, acc: 54.72\n",
      "Epoch: [3 / 5], batches: [700 / 782], loss: 1.276, acc: 54.00\n",
      "Epoch: [4 / 5], batches: [100 / 782], loss: 1.146, acc: 58.80\n",
      "Epoch: [4 / 5], batches: [200 / 782], loss: 1.161, acc: 58.75\n",
      "Epoch: [4 / 5], batches: [300 / 782], loss: 1.126, acc: 60.69\n",
      "Epoch: [4 / 5], batches: [400 / 782], loss: 1.136, acc: 59.72\n",
      "Epoch: [4 / 5], batches: [500 / 782], loss: 1.144, acc: 59.52\n",
      "Epoch: [4 / 5], batches: [600 / 782], loss: 1.144, acc: 59.66\n",
      "Epoch: [4 / 5], batches: [700 / 782], loss: 1.071, acc: 61.50\n",
      "Epoch: [5 / 5], batches: [100 / 782], loss: 0.991, acc: 65.12\n",
      "Epoch: [5 / 5], batches: [200 / 782], loss: 1.013, acc: 64.42\n",
      "Epoch: [5 / 5], batches: [300 / 782], loss: 1.001, acc: 64.67\n",
      "Epoch: [5 / 5], batches: [400 / 782], loss: 0.988, acc: 64.95\n",
      "Epoch: [5 / 5], batches: [500 / 782], loss: 0.953, acc: 66.38\n",
      "Epoch: [5 / 5], batches: [600 / 782], loss: 1.000, acc: 64.39\n",
      "Epoch: [5 / 5], batches: [700 / 782], loss: 0.996, acc: 64.94\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "optimizer_cnn = get_optimizer(cnn_net, 0.01)\n",
    "train(cnn_net, trainloader, optimizer_cnn, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a821c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d23c3f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "test(cnn_net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b273d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
